#!/usr/bin/env python3

"""
VCF Quality Control and Validation Script
Performs comprehensive QC analysis on VCF files generated by the pipeline
"""

import argparse
import gzip
import json
import sys
from collections import Counter
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


class VCFQualityControl:
    """VCF Quality Control analyzer"""

    def __init__(self, vcf_file, output_dir="."):
        self.vcf_file = Path(vcf_file)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.stats = {
            "total_variants": 0,
            "snps": 0,
            "indels": 0,
            "multiallelic": 0,
            "filtered": 0,
            "passed": 0,
            "transitions": 0,
            "transversions": 0,
            "ti_tv_ratio": 0.0,
            "quality_metrics": {
                "mean_qual": 0.0,
                "median_qual": 0.0,
                "mean_dp": 0.0,
                "median_dp": 0.0,
                "mean_gq": 0.0,
                "median_gq": 0.0,
            },
        }

        self.quality_data = {
            "QUAL": [],
            "DP": [],
            "GQ": [],
            "QD": [],
            "FS": [],
            "MQ": [],
            "SOR": [],
        }

        self.variant_types = Counter()
        self.filter_counts = Counter()

    def open_vcf(self):
        """Open VCF file (handles both compressed and uncompressed)"""
        if self.vcf_file.suffix == ".gz":
            return gzip.open(self.vcf_file, "rt")
        else:
            return open(self.vcf_file)

    def parse_info_field(self, info_str):
        """Parse INFO field from VCF"""
        info_dict = {}
        if info_str == ".":
            return info_dict

        for item in info_str.split(";"):
            if "=" in item:
                key, value = item.split("=", 1)
                try:
                    # Try to convert to number
                    if "." in value:
                        info_dict[key] = float(value)
                    else:
                        info_dict[key] = int(value)
                except ValueError:
                    info_dict[key] = value
            else:
                info_dict[item] = True

        return info_dict

    def classify_variant(self, ref, alt):
        """Classify variant type"""
        if len(ref) == 1 and len(alt) == 1:
            # SNP
            if (ref in "AG" and alt in "AG") or (ref in "CT" and alt in "CT"):
                return "transition"
            else:
                return "transversion"
        elif len(ref) != len(alt):
            return "indel"
        else:
            return "complex"

    def analyze_vcf(self):
        """Main analysis function"""
        print(f"Analyzing VCF file: {self.vcf_file}")

        header_lines = []
        variant_count = 0

        with self.open_vcf() as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()

                if line.startswith("#"):
                    header_lines.append(line)
                    continue

                if not line:
                    continue

                try:
                    fields = line.split("\t")
                    if len(fields) < 8:
                        print(f"Warning: Malformed line {line_num}: {line[:50]}...")
                        continue

                    chrom, pos, var_id, ref, alt, qual, filt, info = fields[:8]

                    # Basic variant counting
                    variant_count += 1
                    self.stats["total_variants"] += 1

                    # Filter status
                    if filt == "PASS" or filt == ".":
                        self.stats["passed"] += 1
                    else:
                        self.stats["filtered"] += 1
                        self.filter_counts[filt] += 1

                    # Multiple alleles
                    alts = alt.split(",")
                    if len(alts) > 1:
                        self.stats["multiallelic"] += 1

                    # Process each alternative allele
                    for alt_allele in alts:
                        var_type = self.classify_variant(ref, alt_allele)
                        self.variant_types[var_type] += 1

                        if var_type in ["transition", "transversion"]:
                            self.stats["snps"] += 1
                            if var_type == "transition":
                                self.stats["transitions"] += 1
                            else:
                                self.stats["transversions"] += 1
                        elif var_type == "indel":
                            self.stats["indels"] += 1

                    # Quality metrics
                    try:
                        if qual != ".":
                            qual_val = float(qual)
                            self.quality_data["QUAL"].append(qual_val)
                    except ValueError:
                        pass

                    # Parse INFO field
                    info_dict = self.parse_info_field(info)

                    for key in ["DP", "QD", "FS", "MQ", "SOR"]:
                        if key in info_dict:
                            try:
                                self.quality_data[key].append(float(info_dict[key]))
                            except (ValueError, TypeError):
                                pass

                    # Parse FORMAT and sample columns for GQ
                    if len(fields) >= 10:  # Has sample data
                        fmt = fields[8] if len(fields) > 8 else ""
                        if "GQ" in fmt:
                            fmt_fields = fmt.split(":")
                            if "GQ" in fmt_fields:
                                gq_idx = fmt_fields.index("GQ")
                                for sample_data in fields[9:]:
                                    sample_values = sample_data.split(":")
                                    if len(sample_values) > gq_idx:
                                        try:
                                            gq_val = float(sample_values[gq_idx])
                                            if gq_val != "." and not np.isnan(gq_val):
                                                self.quality_data["GQ"].append(gq_val)
                                        except (ValueError, TypeError):
                                            pass

                except Exception as e:
                    print(f"Error parsing line {line_num}: {e}")
                    print(f"Line: {line[:100]}...")
                    continue

        # Calculate summary statistics
        self.calculate_summary_stats()

        print(f"Analyzed {variant_count} variants")

    def calculate_summary_stats(self):
        """Calculate summary statistics"""
        # Ti/Tv ratio
        if self.stats["transversions"] > 0:
            self.stats["ti_tv_ratio"] = self.stats["transitions"] / self.stats["transversions"]

        # Quality metrics statistics
        for metric in ["QUAL", "DP", "GQ", "QD", "FS", "MQ", "SOR"]:
            if self.quality_data[metric]:
                data = np.array(self.quality_data[metric])
                self.stats["quality_metrics"][f"mean_{metric.lower()}"] = float(np.mean(data))
                self.stats["quality_metrics"][f"median_{metric.lower()}"] = float(np.median(data))
                self.stats["quality_metrics"][f"std_{metric.lower()}"] = float(np.std(data))

    def generate_plots(self):
        """Generate quality control plots"""
        # Set up the plotting style
        plt.style.use("default")

        # Create figure with subplots
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        fig.suptitle(f"VCF Quality Control Report\n{self.vcf_file.name}", fontsize=16)

        # Plot 1: Variant type distribution
        if self.variant_types:
            axes[0, 0].pie(
                self.variant_types.values(), labels=self.variant_types.keys(), autopct="%1.1f%%"
            )
            axes[0, 0].set_title("Variant Types")

        # Plot 2: Quality score distribution
        if self.quality_data["QUAL"]:
            axes[0, 1].hist(self.quality_data["QUAL"], bins=50, alpha=0.7, edgecolor="black")
            axes[0, 1].set_xlabel("Variant Quality (QUAL)")
            axes[0, 1].set_ylabel("Count")
            axes[0, 1].set_title("Quality Score Distribution")

        # Plot 3: Depth distribution
        if self.quality_data["DP"]:
            dp_data = np.array(self.quality_data["DP"])
            # Remove outliers for better visualization
            p95 = np.percentile(dp_data, 95)
            filtered_dp = dp_data[dp_data <= p95]
            axes[0, 2].hist(filtered_dp, bins=50, alpha=0.7, edgecolor="black")
            axes[0, 2].set_xlabel("Read Depth (DP)")
            axes[0, 2].set_ylabel("Count")
            axes[0, 2].set_title("Read Depth Distribution (95th percentile)")

        # Plot 4: Filter status
        filter_data = {"PASS": self.stats["passed"], "FILTERED": self.stats["filtered"]}
        if any(filter_data.values()):
            axes[1, 0].bar(filter_data.keys(), filter_data.values())
            axes[1, 0].set_ylabel("Count")
            axes[1, 0].set_title("Filter Status")

        # Plot 5: Genotype quality distribution
        if self.quality_data["GQ"]:
            axes[1, 1].hist(self.quality_data["GQ"], bins=50, alpha=0.7, edgecolor="black")
            axes[1, 1].set_xlabel("Genotype Quality (GQ)")
            axes[1, 1].set_ylabel("Count")
            axes[1, 1].set_title("Genotype Quality Distribution")

        # Plot 6: Quality by Depth
        if self.quality_data["QD"]:
            axes[1, 2].hist(self.quality_data["QD"], bins=50, alpha=0.7, edgecolor="black")
            axes[1, 2].set_xlabel("Quality by Depth (QD)")
            axes[1, 2].set_ylabel("Count")
            axes[1, 2].set_title("QD Distribution")

        # Remove empty subplots
        for ax in axes.flatten():
            if not ax.has_data():
                ax.set_visible(False)

        plt.tight_layout()

        # Save plot
        plot_file = self.output_dir / f"{self.vcf_file.stem}_qc_plots.png"
        plt.savefig(plot_file, dpi=300, bbox_inches="tight")
        plt.close()

        print(f"QC plots saved to: {plot_file}")

    def generate_report(self):
        """Generate text report"""
        report_file = self.output_dir / f"{self.vcf_file.stem}_qc_report.txt"

        with open(report_file, "w") as f:
            f.write("VCF Quality Control Report\n")
            f.write("=" * 50 + "\n")
            f.write(f"File: {self.vcf_file}\n")
            f.write(f"Analysis Date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")

            f.write("SUMMARY STATISTICS\n")
            f.write("-" * 20 + "\n")
            f.write(f"Total variants: {self.stats['total_variants']:,}\n")
            f.write(
                f"SNPs: {self.stats['snps']:,} ({self.stats['snps'] / max(1, self.stats['total_variants']) * 100:.1f}%)\n"
            )
            f.write(
                f"Indels: {self.stats['indels']:,} ({self.stats['indels'] / max(1, self.stats['total_variants']) * 100:.1f}%)\n"
            )
            f.write(f"Multiallelic sites: {self.stats['multiallelic']:,}\n")
            f.write(
                f"Passed filters: {self.stats['passed']:,} ({self.stats['passed'] / max(1, self.stats['total_variants']) * 100:.1f}%)\n"
            )
            f.write(
                f"Filtered out: {self.stats['filtered']:,} ({self.stats['filtered'] / max(1, self.stats['total_variants']) * 100:.1f}%)\n"
            )
            f.write(f"Ti/Tv ratio: {self.stats['ti_tv_ratio']:.3f}\n\n")

            f.write("QUALITY METRICS\n")
            f.write("-" * 20 + "\n")
            for metric, value in self.stats["quality_metrics"].items():
                if isinstance(value, float):
                    f.write(f"{metric}: {value:.2f}\n")
                else:
                    f.write(f"{metric}: {value}\n")

            f.write("\nVARIANT TYPE BREAKDOWN\n")
            f.write("-" * 25 + "\n")
            for var_type, count in self.variant_types.most_common():
                percentage = count / max(1, sum(self.variant_types.values())) * 100
                f.write(f"{var_type}: {count:,} ({percentage:.1f}%)\n")

            if self.filter_counts:
                f.write("\nFILTER STATUS BREAKDOWN\n")
                f.write("-" * 25 + "\n")
                for filt, count in self.filter_counts.most_common():
                    f.write(f"{filt}: {count:,}\n")

        print(f"QC report saved to: {report_file}")

    def save_json_stats(self):
        """Save statistics as JSON"""
        json_file = self.output_dir / f"{self.vcf_file.stem}_qc_stats.json"

        # Convert numpy types to native Python types for JSON serialization
        json_stats = json.loads(json.dumps(self.stats, default=float))
        json_stats["variant_types"] = dict(self.variant_types)
        json_stats["filter_counts"] = dict(self.filter_counts)

        with open(json_file, "w") as f:
            json.dump(json_stats, f, indent=2)

        print(f"JSON stats saved to: {json_file}")
        return json_stats

    def validate_vcf(self):
        """Basic VCF validation"""
        issues = []

        # Check if file exists and is readable
        if not self.vcf_file.exists():
            issues.append("VCF file does not exist")
            return issues

        # Check file size
        if self.vcf_file.stat().st_size == 0:
            issues.append("VCF file is empty")
            return issues

        # Check header and format
        header_found = False
        column_header_found = False

        try:
            with self.open_vcf() as f:
                for i, line in enumerate(f):
                    if i > 1000:  # Don't read entire large file for validation
                        break

                    line = line.strip()

                    if line.startswith("##fileformat=VCF"):
                        header_found = True
                    elif line.startswith("#CHROM"):
                        column_header_found = True
                        # Check required columns
                        columns = line.split("\t")
                        required_cols = [
                            "#CHROM",
                            "POS",
                            "ID",
                            "REF",
                            "ALT",
                            "QUAL",
                            "FILTER",
                            "INFO",
                        ]
                        for col in required_cols:
                            if col not in columns:
                                issues.append(f"Missing required column: {col}")
                    elif not line.startswith("#"):
                        # Check data line format
                        fields = line.split("\t")
                        if len(fields) < 8:
                            issues.append(f"Data line has too few columns: {len(fields)}")
                        break
        except Exception as e:
            issues.append(f"Error reading VCF file: {e}")

        if not header_found:
            issues.append("Missing VCF file format header")
        if not column_header_found:
            issues.append("Missing column header line")

        return issues


def main():
    parser = argparse.ArgumentParser(
        description="VCF Quality Control Analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Basic QC analysis
  python vcf_qc.py sample.vcf.gz
  
  # Specify output directory
  python vcf_qc.py sample.vcf.gz --output-dir qc_results/
  
  # Validation only
  python vcf_qc.py sample.vcf.gz --validate-only
  
  # Generate all outputs
  python vcf_qc.py sample.vcf.gz --output-dir results/ --plots --json
""",
    )

    parser.add_argument("vcf_file", help="Input VCF file (.vcf or .vcf.gz)")

    parser.add_argument(
        "--output-dir",
        "-o",
        default=".",
        help="Output directory for results (default: current directory)",
    )

    parser.add_argument("--plots", action="store_true", help="Generate quality control plots")

    parser.add_argument("--json", action="store_true", help="Save statistics as JSON file")

    parser.add_argument(
        "--validate-only",
        action="store_true",
        help="Only validate VCF format, do not perform full analysis",
    )

    parser.add_argument(
        "--expected-variants", type=int, help="Expected number of variants (for testing)"
    )

    args = parser.parse_args()

    try:
        # Initialize QC analyzer
        qc = VCFQualityControl(args.vcf_file, args.output_dir)

        # Validate VCF
        print("Validating VCF format...")
        issues = qc.validate_vcf()

        if issues:
            print("VCF validation issues found:")
            for issue in issues:
                print(f"  - {issue}")
            if args.validate_only:
                sys.exit(1)
            else:
                print("Continuing with analysis despite validation issues...")
        else:
            print("VCF validation passed!")

        if args.validate_only:
            print("Validation complete.")
            sys.exit(0)

        # Perform full analysis
        qc.analyze_vcf()

        # Generate outputs
        qc.generate_report()

        if args.plots:
            qc.generate_plots()

        if args.json:
            stats = qc.save_json_stats()
        else:
            stats = qc.stats

        # Check expectations if provided
        if args.expected_variants:
            actual = stats["total_variants"]
            expected = args.expected_variants

            if actual == 0 and expected > 0:
                print(f"ERROR: No variants found, expected {expected}")
                sys.exit(1)
            elif actual != expected:
                print(f"WARNING: Found {actual} variants, expected {expected}")

        # Summary output
        print("\nQC Analysis Complete!")
        print(f"Total variants: {stats['total_variants']:,}")
        print(f"SNPs: {stats['snps']:,}")
        print(f"Indels: {stats['indels']:,}")
        print(f"Ti/Tv ratio: {stats['ti_tv_ratio']:.3f}")
        print(f"Pass rate: {stats['passed'] / (max(1, stats['total_variants'])) * 100:.1f}%")

        # Expected Ti/Tv ratios for validation
        if stats["ti_tv_ratio"] > 0:
            if stats["ti_tv_ratio"] < 1.5 or stats["ti_tv_ratio"] > 4.0:
                print(f"WARNING: Unusual Ti/Tv ratio ({stats['ti_tv_ratio']:.3f})")
                print("Expected: ~2.0-2.1 (WGS), ~2.8-3.0 (Exome)")

    except Exception as e:
        print(f"Error: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
